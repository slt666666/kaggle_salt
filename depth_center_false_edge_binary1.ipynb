{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "depth_center_false_edge_binary1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/slt666666/kaggle_salt/blob/master/depth_center_false_edge_binary1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "oNHydn2Cehdw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 \"sec)\"}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z9Ra67v2QafV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl \n",
        "!pip install -q torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GRMTBCjCQkMb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qu5LXHhneqHa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xCFElSRFeqOH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!wget https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!dpkg -i google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!apt-get install -f\n",
        "!apt-get -y install -qq fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8EbkfB_pe0bq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp drive/kaggle/salt/input.zip ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VNf3guFqe22G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip -q input.zip\n",
        "!mkdir input/test\n",
        "!mkdir input/train\n",
        "!unzip -q input/test.zip\n",
        "!mv images input/test/\n",
        "!unzip -q input/train.zip\n",
        "!mv images input/train/\n",
        "!mv masks input/train/\n",
        "!rm input.zip\n",
        "!rm input/test.zip\n",
        "!rm input/train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GKtT18VAOpNF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "directory = 'input'\n",
        "seed = 78\n",
        "fold = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rEoyKgYpQ_Xf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ResNet\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes,\n",
        "                     kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class ChannelGate2d(nn.Module):\n",
        "\n",
        "    def __init__(self, channels, reduction=2):\n",
        "        super(ChannelGate2d, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
        "                             padding=0)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
        "                             padding=0)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        module_input = x\n",
        "        x = self.avg_pool(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return module_input * x\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, activation=None, SE=False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.SE = SE\n",
        "        if activation is None:\n",
        "            self.activation = nn.ReLU(inplace=True)\n",
        "        else:\n",
        "            self.activation = activation\n",
        "\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        if SE:\n",
        "            self.cSE = ChannelGate2d(planes, reduction=16)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.activation(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        if self.SE:\n",
        "            out = self.cSE(out)\n",
        "\n",
        "        out += residual\n",
        "        out = self.activation(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, activation=None, SE=False):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.SE = SE\n",
        "        if activation is None:\n",
        "            self.activation = nn.ReLU(inplace=True)\n",
        "        else:\n",
        "            self.activation = activation\n",
        "\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        if SE:\n",
        "            self.cSE = ChannelGate2d(planes, reduction=16)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.activation(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.activation(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        if self.SE:\n",
        "            out = self.cSE(out)\n",
        "\n",
        "        out += residual\n",
        "        out = self.activation(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, activation=None, num_classes=1000, SE=False):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.SE = SE\n",
        "        self.inplanes = 64\n",
        "        if activation is None:\n",
        "            self.activation = nn.ReLU(inplace=True)\n",
        "        else:\n",
        "            self.activation = activation\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7,\n",
        "                               stride=1, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, activation=self.activation, SE=self.SE))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, activation=self.activation, SE=self.SE))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def resnet34(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']), strict=False)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_pretrain_file(net, pretrain_file, skip=['cSE']):\n",
        "    pretrain_state_dict = torch.load(pretrain_file)\n",
        "    state_dict = net.state_dict()\n",
        "    keys = list(state_dict.keys())\n",
        "    for key in keys:\n",
        "        if any(s in key for s in skip):\n",
        "            continue\n",
        "        else:\n",
        "            state_dict[key] = pretrain_state_dict[key]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D6fJZ_b6OpP7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import random\n",
        "import time\n",
        "\n",
        "class ELU_1(nn.ELU):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(ELU_1, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.elu(input, self.alpha, self.inplace)\n",
        "\n",
        "class ConvBn2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels,\n",
        "                 kernel_size=(3, 3), stride=(1, 1),\n",
        "                 padding=(1, 1), groups=1, dilation=1):\n",
        "        super(ConvBn2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
        "                              kernel_size=kernel_size,\n",
        "                              stride=stride,\n",
        "                              padding=padding,\n",
        "                              bias=False,\n",
        "                              groups=groups,\n",
        "                              dilation=dilation)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "class CenterBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, pool=True, SE=False):\n",
        "        super(CenterBlock, self).__init__()\n",
        "        self.SE = SE\n",
        "        self.pool = pool\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = ConvBn2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.conv2 = ConvBn2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.conv_res = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0)\n",
        "        if SE:\n",
        "            self.se = scSqueezeExcitationGate(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.pool:\n",
        "            x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        residual = self.conv_res(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        if self.SE:\n",
        "            x = self.se(x)\n",
        "\n",
        "        x += residual\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class SpatialGate2d(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels):\n",
        "        super(SpatialGate2d, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 1, kernel_size=1, stride=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        cal = self.conv1(x)\n",
        "        cal = self.sigmoid(cal)\n",
        "        return cal * x\n",
        "\n",
        "class ChannelGate2d(nn.Module):\n",
        "\n",
        "    def __init__(self, channels, reduction=2):\n",
        "        super(ChannelGate2d, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
        "                             padding=0)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
        "                             padding=0)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        module_input = x\n",
        "        x = self.avg_pool(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return module_input * x\n",
        "      \n",
        "class scSqueezeExcitationGate(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(scSqueezeExcitationGate, self).__init__()\n",
        "        self.spatial_gate = SpatialGate2d(channels)\n",
        "        self.channel_gate = ChannelGate2d(channels, reduction=reduction)\n",
        "\n",
        "    def  forward(self, x, z=None):\n",
        "        XsSE = self.spatial_gate(x)\n",
        "        XcSe = self.channel_gate(x)\n",
        "        return XsSE + XcSe\n",
        "\n",
        "class PyramidPoolingModule(nn.Module):\n",
        "    def __init__(self, pool_list, in_channels, size=(128, 128)):\n",
        "        super(PyramidPoolingModule, self).__init__()\n",
        "        self.size = size\n",
        "        self.pool_list = pool_list\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=1, stride=1, padding=0) for _ in range(len(pool_list))])\n",
        "        self.conv2 = nn.Conv2d(in_channels + len(pool_list), in_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        cat = [x]\n",
        "        for (k, s), conv in zip(self.pool_list, self.conv1):\n",
        "            out = F.avg_pool2d(x, kernel_size=k, stride=s)\n",
        "            out = conv(out)\n",
        "            out = F.upsample(out, size=self.size, mode='bilinear', align_corners=True)\n",
        "            cat.append(out)\n",
        "        out = torch.cat(cat, 1)\n",
        "        out = self.conv2(out)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "      \n",
        "class Decoder_v3(nn.Module):\n",
        "    def __init__(self, in_channels, convT_channels, out_channels, convT_ratio=2, SE=False):\n",
        "        super(Decoder_v3, self).__init__()\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.SE = SE\n",
        "        self.convT = nn.ConvTranspose2d(convT_channels, convT_channels // convT_ratio, kernel_size=2, stride=2)\n",
        "        self.conv1 = ConvBn2d(in_channels  + convT_channels // convT_ratio, out_channels)\n",
        "        self.conv2 = ConvBn2d(out_channels, out_channels)\n",
        "        if SE:\n",
        "            self.scSE = scSqueezeExcitationGate(out_channels)\n",
        "\n",
        "        self.conv_res = nn.Conv2d(convT_channels // convT_ratio, out_channels, kernel_size=1, padding=0)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.convT(x)\n",
        "        residual = x\n",
        "        x = torch.cat([x, skip], 1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        if self.SE:\n",
        "            x = self.scSE(x)\n",
        "        x += self.conv_res(residual)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class UNetResNet34_SE_Hyper_SPP(nn.Module):\n",
        "    # PyTorch U-Net model using ResNet(34, 50 , 101 or 152) encoder.\n",
        "\n",
        "    def __init__(self, pretrained=True, activation='relu', **kwargs):\n",
        "        super(UNetResNet34_SE_Hyper_SPP, self).__init__(**kwargs)\n",
        "        if activation == 'relu':\n",
        "            self.activation = nn.ReLU(inplace=True)\n",
        "        elif activation == 'elu':\n",
        "            self.activation = ELU_1(inplace=True)\n",
        "\n",
        "        self.resnet = resnet34(pretrained=pretrained, activation=self.activation, SE=True)\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            self.resnet.conv1,\n",
        "            self.resnet.bn1,\n",
        "            self.resnet.activation,\n",
        "        )  # 64\n",
        "\n",
        "        self.encoder1 = self.resnet.layer1  # 64\n",
        "        self.encoder2 = self.resnet.layer2  # 128\n",
        "        self.encoder3 = self.resnet.layer3  # 256\n",
        "        self.encoder4 = self.resnet.layer4  # 512\n",
        "\n",
        "        self.center = CenterBlock(512, 64, pool=False, SE=False)\n",
        "\n",
        "        self.decoder4 = Decoder_v3(256, 64,  64, convT_ratio=1,  SE=True)\n",
        "        self.decoder3 = Decoder_v3(128, 64,  64, convT_ratio=1,  SE=True)\n",
        "        self.decoder2 = Decoder_v3(64,  64,  64, convT_ratio=1,  SE=True)\n",
        "        self.decoder1 = Decoder_v3(64,  64,  64, convT_ratio=1,  SE=True)\n",
        "\n",
        "        self.reducer = ConvBn2d(64 * 5, 64, kernel_size=1, padding=0)\n",
        "\n",
        "        self.logit_pixel  = nn.Sequential(\n",
        "            nn.Conv2d(320, 64, kernel_size=3, padding=1),\n",
        "#             ConvBn2d(64 * 5, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d( 64,  1, kernel_size=1, padding=0),\n",
        "        )\n",
        "\n",
        "        self.logit_image = nn.Sequential(\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 1),\n",
        "        )\n",
        "\n",
        "        self.logit = nn.Sequential(\n",
        "            ConvBn2d(64 * 5 + 512, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 1, kernel_size=1, padding=0),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # batch_size,C,H,W = x.shape\n",
        "        mean=[0.485, 0.456, 0.406]\n",
        "        std =[0.229, 0.224, 0.225]\n",
        "        x = torch.cat([\n",
        "            (x-mean[0])/std[0],\n",
        "            (x-mean[1])/std[1],\n",
        "            (x-mean[2])/std[2],\n",
        "        ],1)\n",
        "\n",
        "        x = self.conv1(x) # 128\n",
        "        p = F.max_pool2d(x, kernel_size=2, stride=2) # 64\n",
        "\n",
        "        e1 = self.encoder1(p)   # 64\n",
        "        e2 = self.encoder2(e1)  # 32\n",
        "        e3 = self.encoder3(e2)  # 16\n",
        "        e4 = self.encoder4(e3)  # 8\n",
        "\n",
        "        c = self.center(e4)  # 8\n",
        "\n",
        "        d4 = self.decoder4(c, e3)  # 16\n",
        "        d3 = self.decoder3(d4, e2)  # 32\n",
        "        d2 = self.decoder2(d3, e1)  # 64\n",
        "        d1 = self.decoder1(d2, x)   # 128\n",
        "\n",
        "        f = torch.cat([\n",
        "            d1,\n",
        "            F.upsample(d2, scale_factor=2,  mode='bilinear', align_corners=False),\n",
        "            F.upsample(d3, scale_factor=4,  mode='bilinear', align_corners=False),\n",
        "            F.upsample(d4, scale_factor=8,  mode='bilinear', align_corners=False),\n",
        "            F.upsample(c,  scale_factor=16, mode='bilinear', align_corners=False)\n",
        "            ], 1)\n",
        "\n",
        "        batch_size = f.size()[0]\n",
        "#         fuse_pixel  = self.fuse_pixel(f)\n",
        "        fuse_pixel  = f\n",
        "        logit_pixel = self.logit_pixel(f)\n",
        "        \n",
        "        e = F.adaptive_avg_pool2d(e4, output_size=1).view(batch_size,-1) #image pool\n",
        "#         fuse_image  = self.fuse_image(e)\n",
        "        fuse_image  = e\n",
        "        logit_image = self.logit_image(fuse_image).view(-1)\n",
        "        \n",
        "        fuse = torch.cat([ #fuse\n",
        "            fuse_pixel,\n",
        "            F.upsample(fuse_image.view(batch_size,-1,1,1,),scale_factor=128, mode='nearest')\n",
        "        ],1)\n",
        "        logit = self.logit(fuse)\n",
        "        return logit, logit_pixel, logit_image\n",
        "        \n",
        "    def criterion1(self, logit, truth ):\n",
        "        loss = RobustFocalLoss2d()(logit, truth, type='sigmoid')\n",
        "        return loss\n",
        "      \n",
        "    def criterion2(self, logit, truth ):\n",
        "        loss = LovaszLoss()(logit, truth)\n",
        "        return loss\n",
        "\n",
        "    def criterion(self, logit, logit_pixel, logit_image, truth_pixel, is_average=True):\n",
        "        truth_image = truth_pixel.squeeze(1)\n",
        "        truth_image = torch.sum(truth_image, (1, 2)).ge(0.1).float()\n",
        "        loss_image = F.binary_cross_entropy_with_logits(logit_image, truth_image, reduce=is_average)\n",
        "\n",
        "        loss_pixel = LovaszLoss()(logit_pixel, truth_pixel)\n",
        "        #loss_pixel = FocalLoss2d(size_average=False)(logit_pixel, truth_pixel, type='sigmoid')\n",
        "        loss_pixel = loss_pixel*truth_image.cpu().numpy() #loss for empty image is weighted 0\n",
        "        if is_average:\n",
        "            if truth_image.sum() == 0:\n",
        "                loss_pixel = 0\n",
        "            else:\n",
        "                loss_pixel = loss_pixel.sum()/truth_image.sum()\n",
        "\n",
        "        loss_all = LovaszLoss()(logit, truth_pixel, per_image=False)\n",
        "        #loss_all = FocalLoss2d(size_average=False)(logit, truth_pixel, type='sigmoid')\n",
        "        \n",
        "        weight_pixel = 0.5\n",
        "        weight_image = 0.05\n",
        "        weight_all = 1.0\n",
        "\n",
        "        return weight_pixel*loss_pixel + weight_image*loss_image + weight_all*loss_all\n",
        "\n",
        "    def metric(self, logit, truth):\n",
        "#         iou = iou_pytorch(logit, truth)\n",
        "        pred = torch.sigmoid(logit)\n",
        "        dice = dice_accuracy(pred, truth)\n",
        "        return dice\n",
        "#         return iou\n",
        " \n",
        "    def set_mode(self, mode ):\n",
        "        self.mode = mode\n",
        "        if mode in ['eval', 'valid', 'test']:\n",
        "            self.eval()\n",
        "        elif mode in ['train']:\n",
        "            self.train()\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "SaltNet =  UNetResNet34_SE_Hyper_SPP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VeM1CmJK2rmU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "class RobustFocalLoss2d(nn.Module):\n",
        "    #assume top 10% is outliers\n",
        "    def __init__(self, gamma=2, size_average=True):\n",
        "        super(RobustFocalLoss2d, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.size_average = size_average\n",
        "\n",
        "\n",
        "    def forward(self, logit, target, class_weight=None, type='softmax'):\n",
        "        target = target.view(-1, 1).long()\n",
        "\n",
        "\n",
        "        if type=='sigmoid':\n",
        "            if class_weight is None:\n",
        "                class_weight = [1]*2 #[0.5, 0.5]\n",
        "\n",
        "            prob   = torch.sigmoid(logit)\n",
        "            prob   = prob.view(-1, 1)\n",
        "            prob   = torch.cat((1-prob, prob), 1)\n",
        "            select = torch.FloatTensor(len(prob), 2).zero_().cuda()\n",
        "            select.scatter_(1, target, 1.)\n",
        "\n",
        "        elif  type=='softmax':\n",
        "            B,C,H,W = logit.size()\n",
        "            if class_weight is None:\n",
        "                class_weight =[1]*C #[1/C]*C\n",
        "\n",
        "            logit   = logit.permute(0, 2, 3, 1).contiguous().view(-1, C)\n",
        "            prob    = F.softmax(logit,1)\n",
        "            select  = torch.FloatTensor(len(prob), C).zero_().cuda()\n",
        "            select.scatter_(1, target, 1.)\n",
        "\n",
        "        class_weight = torch.FloatTensor(class_weight).cuda().view(-1,1)\n",
        "        class_weight = torch.gather(class_weight, 0, target)\n",
        "\n",
        "        prob  = (prob*select).sum(1).view(-1,1)\n",
        "        prob  = torch.clamp(prob,1e-8,1-1e-8)\n",
        "\n",
        "        focus = torch.pow((1-prob), self.gamma)\n",
        "        #focus = torch.where(focus < 2.0, focus, torch.zeros(prob.size()).cuda())\n",
        "        focus = torch.clamp(focus,0,2)\n",
        "\n",
        "\n",
        "        batch_loss = - class_weight *focus*prob.log()\n",
        "\n",
        "        if self.size_average:\n",
        "            loss = batch_loss.mean()\n",
        "        else:\n",
        "            loss = batch_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "# Lovasz\n",
        "try:\n",
        "    from itertools import  ifilterfalse\n",
        "except ImportError: # py3k\n",
        "    from itertools import  filterfalse\n",
        "    \n",
        "def mean(l, ignore_nan=False, empty=0):\n",
        "    \"\"\"\n",
        "    nanmean compatible with generators.\n",
        "    \"\"\"\n",
        "    l = iter(l)\n",
        "    if ignore_nan:\n",
        "        l = ifilterfalse(np.isnan, l)\n",
        "    try:\n",
        "        n = 1\n",
        "        acc = next(l)\n",
        "    except StopIteration:\n",
        "        if empty == 'raise':\n",
        "            raise ValueError('Empty mean')\n",
        "        return empty\n",
        "    for n, v in enumerate(l, 2):\n",
        "        acc += v\n",
        "    if n == 1:\n",
        "        return acc\n",
        "    return acc / n\n",
        "\n",
        "def lovasz_grad(gt_sorted):\n",
        "    \"\"\"\n",
        "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
        "    See Alg. 1 in paper\n",
        "    \"\"\"\n",
        "    p = len(gt_sorted)\n",
        "    gts = gt_sorted.sum()\n",
        "    intersection = gts - gt_sorted.float().cumsum(0)\n",
        "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
        "    jaccard = 1. - intersection / union\n",
        "    if p > 1: # cover 1-pixel case\n",
        "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
        "    return jaccard\n",
        "  \n",
        "def lovasz_hinge_flat(logits, labels):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
        "      ignore: label to ignore\n",
        "    \"\"\"\n",
        "    if len(labels) == 0:\n",
        "        # only void pixels, the gradients should be 0\n",
        "        return logits.sum() * 0.\n",
        "    signs = 2. * labels.float() - 1.\n",
        "    errors = (1. - logits * Variable(signs))\n",
        "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
        "    perm = perm.data\n",
        "    gt_sorted = labels[perm]\n",
        "    grad = lovasz_grad(gt_sorted)\n",
        "    loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def flatten_binary_scores(scores, labels, ignore=None):\n",
        "    \"\"\"\n",
        "    Flattens predictions in the batch (binary case)\n",
        "    Remove labels equal to 'ignore'\n",
        "    \"\"\"\n",
        "    scores = scores.contiguous()\n",
        "    scores = scores.view(-1)\n",
        "    labels = labels.contiguous()\n",
        "    labels = labels.view(-1)\n",
        "    if ignore is None:\n",
        "        return scores, labels\n",
        "    valid = (labels != ignore)\n",
        "    vscores = scores[valid]\n",
        "    vlabels = labels[valid]\n",
        "    return vscores, vlabels\n",
        "\n",
        "def unpad_im(im, pad=((13, 14), (13, 14))):\n",
        "    im = im[:, :, pad[0][0]:-pad[0][1], pad[1][0]:-pad[1][1]]\n",
        "    return im\n",
        "\n",
        "class LovaszLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LovaszLoss, self).__init__()\n",
        "\n",
        "    def forward(self, logits, labels, per_image=True, ignore=None):\n",
        "        \"\"\"\n",
        "        Binary Lovasz hinge loss\n",
        "          logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
        "          labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
        "          per_image: compute the loss per image instead of per batch\n",
        "          ignore: void class id\n",
        "        \"\"\"\n",
        "        logits = unpad_im(logits)\n",
        "        labels = unpad_im(labels)\n",
        "        if per_image:\n",
        "            loss = [lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore)) for log, lab in zip(logits, labels)]\n",
        "        else:\n",
        "            loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n",
        "                              for log, lab in zip(logits, labels))\n",
        "#             loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-Qlwu70VxdQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# metric function\n",
        "def unpad_im(im, pad=((13, 14), (13, 14))):\n",
        "    im = im[:, :, pad[0][0]:-pad[0][1], pad[1][0]:-pad[1][1]]\n",
        "    return im\n",
        "\n",
        "def dice_accuracy(prob, truth, threshold=0.5, is_average=True, smooth=1e-12):\n",
        "    prob = unpad_im(prob)\n",
        "    truth = unpad_im(truth)\n",
        "\n",
        "    batch_size = prob.size(0)\n",
        "    p = prob.detach().contiguous().view(batch_size, -1)\n",
        "    t = truth.detach().contiguous().view(batch_size, -1)\n",
        "\n",
        "    p = p > threshold\n",
        "    t = t > 0.5\n",
        "    intersection = p & t\n",
        "    union = p | t\n",
        "    dice = (intersection.float().sum(1) + smooth) / (union.float().sum(1) + smooth)\n",
        "\n",
        "    if is_average:\n",
        "        dice = dice.sum() / batch_size\n",
        "\n",
        "    return dice\n",
        "\n",
        "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor, lovasz=True):\n",
        "    smooth = 1e-10\n",
        "    outputs = outputs.squeeze(1)\n",
        "    if lovasz:\n",
        "       outputs = outputs > 0\n",
        "    else:\n",
        "       outputs = outputs > 0.5\n",
        "    labels = labels.squeeze(1).byte()\n",
        "    intersection = (outputs & labels).sum(dim=(1, 2)).float()\n",
        "    union = (outputs | labels).sum(dim=(1, 2)).float() \n",
        "    \n",
        "    iou = (intersection + smooth) / (union + smooth)\n",
        "    \n",
        "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10\n",
        "    thresholded = thresholded.mean()\n",
        "    return thresholded "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_65g96VOOpVf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_depth_channels(image): # (101, 101, 3)\n",
        "    image = image.astype('float32')\n",
        "    h, w, _ = image.shape\n",
        "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
        "        image[row, :, 1] = const\n",
        "    image[:, :, 2] = image[:, :, 0] * image[:, :, 1]\n",
        "    image[:, :, 1] = image[:, :, 2]\n",
        "    return image\n",
        "\n",
        "def load_test_image(image_path):\n",
        "    \"\"\"\n",
        "    Load image from a given path and resize, so that eash side is divisible by 32 (newtwork requirement)\n",
        "\n",
        "    \"\"\"\n",
        "    img = cv2.imread(str(image_path))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = add_depth_channels(img)\n",
        "    \n",
        "    reflect_img = cv2.flip(img, 1)\n",
        "    \n",
        "    img = cv2.copyMakeBorder(img, 13, 14, 13, 14, cv2.BORDER_REPLICATE)\n",
        "    reflect_img = cv2.copyMakeBorder(reflect_img, 13, 14, 13, 14, cv2.BORDER_REPLICATE)\n",
        "\n",
        "    img = img[:, :, 0:1] / 255.0\n",
        "    reflect_img = reflect_img[:, :, 0:1] / 255.0\n",
        "    return torch.from_numpy(np.transpose(img, (2, 0, 1)).astype('float32')), torch.from_numpy(np.transpose(reflect_img, (2, 0, 1)).astype('float32'))\n",
        "\n",
        "def load_valid_image(image_path, mask_path):\n",
        "    \"\"\"\n",
        "    Load image from a given path and resize, so that eash side is divisible by 32 (newtwork requirement)\n",
        "\n",
        "    \"\"\"\n",
        "    img = cv2.imread(str(image_path))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = add_depth_channels(img)\n",
        "    \n",
        "    msk = cv2.imread(str(mask_path))\n",
        "    msk = cv2.cvtColor(msk, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    img = cv2.copyMakeBorder(img, 13, 14, 13, 14, cv2.BORDER_REPLICATE)\n",
        "    msk = cv2.copyMakeBorder(msk, 13, 14, 13, 14, cv2.BORDER_REPLICATE)\n",
        "    \n",
        "    img = img[:, :, 0:1] / 255.0\n",
        "    msk = msk[:, :, 0:1] // 255\n",
        "  \n",
        "    return torch.from_numpy(np.transpose(img, (2, 0, 1)).astype('float32')), torch.from_numpy(np.transpose(msk, (2, 0, 1)).astype('float32'))\n",
        "\n",
        "def load_train_image(image_path, mask_path): \n",
        "    \"\"\"\n",
        "    Load image from a given path and resize, so that eash side is divisible by 32 (newtwork requirement)\n",
        "\n",
        "    \"\"\"\n",
        "    img = cv2.imread(str(image_path))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    msk = cv2.imread(str(mask_path))\n",
        "    msk = cv2.cvtColor(msk, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # flip\n",
        "    if np.random.rand() < 0.5:\n",
        "        img = cv2.flip(img, 1)\n",
        "        msk = cv2.flip(msk, 1)\n",
        "    \n",
        "#     # bright\n",
        "#     if np.random.rand() < 0.5:\n",
        "#         gamma = np.random.uniform(0.92, 1.08)\n",
        "#         gamma_cvt = np.zeros((256,1),dtype = 'uint8')\n",
        "\n",
        "#         for i in range(256):\n",
        "#             gamma_cvt[i][0] = 255 * (float(i)/255) ** (1.0/gamma)\n",
        "#         img = cv2.LUT(img, gamma_cvt)\n",
        "    \n",
        "    # random crop | affine | zoom\n",
        "#     if np.random.rand() < 0.5:\n",
        "#         c = np.random.choice(2)\n",
        "#         if c == 0:\n",
        "#             x, y = np.random.randint(1, 12), np.random.randint(1, 12)\n",
        "#             img = img[y:90 + y, x:90 + x, :]\n",
        "#             img = cv2.resize(img, (101, 101))\n",
        "#             msk = msk[y:90 + y, x:90 + x, :]\n",
        "#             msk = cv2.resize(msk, (101, 101))\n",
        "        \n",
        "#         if c == 1:\n",
        "#             x, y = np.random.randint(1, 5), np.random.randint(1, 5)\n",
        "#             z = np.random.randint(1, x+y)\n",
        "#             pts1 = np.float32([[0,0],[101,0],[101,101]])\n",
        "#             pts2 = np.float32([[0-x,0],[101+y,0],[101+z,101]])\n",
        "#             M = cv2.getAffineTransform(pts1,pts2)\n",
        "#             img = cv2.warpAffine(img,M,(101,101))\n",
        "#             msk = cv2.warpAffine(msk,M,(101,101))\n",
        "    img = add_depth_channels(img)\n",
        "    img = cv2.copyMakeBorder(img, 13, 14, 13, 14, cv2.BORDER_REPLICATE)\n",
        "    msk = cv2.copyMakeBorder(msk, 13, 14, 13, 14, cv2.BORDER_REPLICATE)\n",
        "    \n",
        "    img = img[:, :, 0:1] / 255.0\n",
        "    msk = msk[:, :, 0:1] // 255\n",
        "  \n",
        "    return torch.from_numpy(np.transpose(img, (2, 0, 1)).astype('float32')), torch.from_numpy(np.transpose(msk, (2, 0, 1)).astype('float32'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H3MUztUwOpaF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapted from vizualization kernel\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from torch.utils import data\n",
        "\n",
        "class TGSSaltDataset(data.Dataset):\n",
        "    def __init__(self, root_path, file_list, is_test = False, is_valid = False):\n",
        "        self.is_test = is_test\n",
        "        self.is_valid = is_valid\n",
        "        self.root_path = root_path\n",
        "        self.file_list = file_list\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if index not in range(0, len(self.file_list)):\n",
        "            return self.__getitem__(np.random.randint(0, self.__len__()))\n",
        "        \n",
        "        file_id = self.file_list[index]\n",
        "        \n",
        "        image_folder = os.path.join(self.root_path, \"images\")\n",
        "        image_path = os.path.join(image_folder, file_id + \".png\")\n",
        "        \n",
        "        mask_folder = os.path.join(self.root_path, \"masks\")\n",
        "        mask_path = os.path.join(mask_folder, file_id + \".png\")\n",
        "        \n",
        "        if self.is_test:\n",
        "            image, reflect_image = load_test_image(image_path)\n",
        "            return image, reflect_image\n",
        "        elif self.is_valid:\n",
        "            image, mask = load_valid_image(image_path, mask_path)\n",
        "            return image, mask\n",
        "        else:\n",
        "            image, mask = load_train_image(image_path, mask_path)\n",
        "            return image, mask\n",
        "\n",
        "depths_df = pd.read_csv(os.path.join(directory, 'train.csv'))\n",
        "\n",
        "train_path = os.path.join(directory, 'train')\n",
        "file_list = list(depths_df['id'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yd8y5gEmOpYp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/leigh-plt/cs231n_hw2018/blob/master/assignment2/pytorch_tutorial.ipynb\n",
        "def save_checkpoint(checkpoint_path, model, optimizer):\n",
        "    state = {'state_dict': model.state_dict(),\n",
        "             'optimizer' : optimizer.state_dict()}\n",
        "    torch.save(state, checkpoint_path)\n",
        "    print('model saved to %s' % checkpoint_path)\n",
        "    \n",
        "def load_checkpoint(checkpoint_path, model, optimizer):\n",
        "    state = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(state['state_dict'])\n",
        "    optimizer.load_state_dict(state['optimizer'])\n",
        "    print('model loaded from %s' % checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lSVp9KQ_O92X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_ids = pd.read_csv(\"drive/kaggle/salt/seed/valid_index_seed{}_{}.csv\".format(seed, fold), header=None)\n",
        "file_list_val = list(valid_ids[0].values)\n",
        "file_list_train = [f for f in file_list if f not in file_list_val]\n",
        "dataset = TGSSaltDataset(train_path, file_list_train)\n",
        "dataset_val = TGSSaltDataset(train_path, file_list_val, is_valid=True)\n",
        "\n",
        "# First train\n",
        "model = SaltNet().cuda()\n",
        "\n",
        "epoch = 30\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
        "# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=10, min_lr=0.001)\n",
        "\n",
        "best_iou = 0\n",
        "\n",
        "for e in range(epoch):\n",
        "    start = time.time()\n",
        "    train_loss = []\n",
        "    train_iou = []\n",
        "    model.set_mode('train')\n",
        "    for image, mask in tqdm(data.DataLoader(dataset, batch_size = 16, shuffle = True)):\n",
        "      \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        image = image.type(torch.FloatTensor).cuda()\n",
        "        logit, logit_pixel, logit_image = model(Variable(image))\n",
        "        loss = model.criterion(logit, logit_pixel, logit_image, Variable(mask.cuda()))\n",
        "        iou = model.metric(logit, Variable(mask.cuda()))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss.append(loss.data)\n",
        "        train_iou.append(iou.data)\n",
        "        \n",
        "    val_loss = []\n",
        "    val_iou = []\n",
        "    model.set_mode('valid')\n",
        "    for image, mask in data.DataLoader(dataset_val, batch_size = 16, shuffle = False):\n",
        "        image = image.type(torch.FloatTensor).cuda()\n",
        "        logit, logit_pixel, logit_image = model(Variable(image))\n",
        "        loss = model.criterion(logit, logit_pixel, logit_image, Variable(mask.cuda()))\n",
        "        iou = model.metric(logit, Variable(mask.cuda()))\n",
        "        val_loss.append(loss.data)\n",
        "        val_iou.append(iou.data)\n",
        "    \n",
        "#     scheduler.step(np.mean(val_iou))\n",
        "\n",
        "    if np.mean(val_iou) > best_iou:\n",
        "        best_iou = np.mean(val_iou)\n",
        "        save_checkpoint('drive/model/seed{}_{}_scSE_binary_model1.pth'.format(seed, fold), model, optimizer)\n",
        "\n",
        "    print(\"{}s \\n\".format(time.time() - start))\n",
        "    print(\"Epoch: %d, Train_loss: %.3f, Train_iou: %.3f, Val_loss: %.3f, Val_iou: %.3f\" % (e, np.mean(train_loss), np.mean(train_iou), np.mean(val_loss), np.mean(val_iou)))\n",
        "# save the final model\n",
        "# save_checkpoint('tgs-%i.pth' % epoch, model, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5kLlz7_SURg8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Second train\n",
        "load_checkpoint('drive/model/seed{}_{}_scSE_binary_model1.pth'.format(seed, fold), model, optimizer)\n",
        "\n",
        "epoch = 30\n",
        "learning_rate = 0.005\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=6, min_lr=0.001)\n",
        "\n",
        "best_iou = 0\n",
        "\n",
        "for e in range(epoch):\n",
        "    start = time.time()\n",
        "    train_loss = []\n",
        "    train_iou = []\n",
        "    model.set_mode('train')\n",
        "    for image, mask in tqdm(data.DataLoader(dataset, batch_size = 16, shuffle = True)):\n",
        "      \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        image = image.type(torch.FloatTensor).cuda()\n",
        "        logit, logit_pixel, logit_image = model(Variable(image))\n",
        "        loss = model.criterion(logit, logit_pixel, logit_image, Variable(mask.cuda()))\n",
        "        iou = model.metric(logit, Variable(mask.cuda()))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss.append(loss.data)\n",
        "        train_iou.append(iou.data)\n",
        "        \n",
        "    val_loss = []\n",
        "    val_iou = []\n",
        "    model.set_mode('valid')\n",
        "    for image, mask in data.DataLoader(dataset_val, batch_size = 16, shuffle = False):\n",
        "        image = image.type(torch.FloatTensor).cuda()\n",
        "        logit, logit_pixel, logit_image = model(Variable(image))\n",
        "        loss = model.criterion(logit, logit_pixel, logit_image, Variable(mask.cuda()))\n",
        "        iou = model.metric(logit, Variable(mask.cuda()))\n",
        "        val_loss.append(loss.data)\n",
        "        val_iou.append(iou.data)\n",
        "    \n",
        "    scheduler.step(np.mean(val_iou))\n",
        "\n",
        "    if np.mean(val_iou) > best_iou:\n",
        "        best_iou = np.mean(val_iou)\n",
        "        save_checkpoint('drive/model/seed{}_{}_scSE_binary_model2.pth'.format(seed, fold), model, optimizer)\n",
        "\n",
        "    print(\"{}s \\n\".format(time.time() - start))\n",
        "    print(\"Epoch: %d, Train_loss: %.3f, Train_iou: %.3f, Val_loss: %.3f, Val_iou: %.3f\" % (e, np.mean(train_loss), np.mean(train_iou), np.mean(val_loss), np.mean(val_iou)))\n",
        "# save the final model\n",
        "# save_checkpoint('tgs-%i.pth' % epoch, model, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xv19Xawf493P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Third train\n",
        "load_checkpoint('drive/model/seed{}_{}_scSE_binary_model2.pth'.format(seed, fold), model, optimizer)\n",
        "\n",
        "epoch = 30\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=6, min_lr=0.0001)\n",
        "\n",
        "best_iou = 0\n",
        "\n",
        "for e in range(epoch):\n",
        "    start = time.time()\n",
        "    train_loss = []\n",
        "    train_iou = []\n",
        "    model.set_mode('train')\n",
        "    for image, mask in tqdm(data.DataLoader(dataset, batch_size = 16, shuffle = True)):\n",
        "      \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        image = image.type(torch.FloatTensor).cuda()\n",
        "        logit, logit_pixel, logit_image = model(Variable(image))\n",
        "        loss = model.criterion(logit, logit_pixel, logit_image, Variable(mask.cuda()))\n",
        "        iou = model.metric(logit, Variable(mask.cuda()))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss.append(loss.data)\n",
        "        train_iou.append(iou.data)\n",
        "        \n",
        "    val_loss = []\n",
        "    val_iou = []\n",
        "    model.set_mode('valid')\n",
        "    for image, mask in data.DataLoader(dataset_val, batch_size = 16, shuffle = False):\n",
        "        image = image.type(torch.FloatTensor).cuda()\n",
        "        logit, logit_pixel, logit_image = model(Variable(image))\n",
        "        loss = model.criterion(logit, logit_pixel, logit_image, Variable(mask.cuda()))\n",
        "        iou = model.metric(logit, Variable(mask.cuda()))\n",
        "        val_loss.append(loss.data)\n",
        "        val_iou.append(iou.data)\n",
        "    \n",
        "    scheduler.step(np.mean(val_iou))\n",
        "\n",
        "    if np.mean(val_iou) > 0.865:\n",
        "        best_iou = np.mean(val_iou)\n",
        "        save_checkpoint('drive/model/seed{}_{}_scSE_binary_model3.pth'.format(seed, fold), model, optimizer)\n",
        "\n",
        "    print(\"{}s \\n\".format(time.time() - start))\n",
        "    print(\"Epoch: %d, Train_loss: %.3f, Train_iou: %.3f, Val_loss: %.3f, Val_iou: %.3f\" % (e, np.mean(train_loss), np.mean(train_iou), np.mean(val_loss), np.mean(val_iou)))\n",
        "# save the final model\n",
        "# save_checkpoint('tgs-%i.pth' % epoch, model, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vq_74-K3tCf1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_ids = pd.read_csv(\"drive/kaggle/salt/seed/valid_index_seed{}_{}.csv\".format(seed, fold), header=None)\n",
        "file_list_val = list(valid_ids[0].values)\n",
        "file_list_train = [f for f in file_list if f not in file_list_val]\n",
        "dataset = TGSSaltDataset(train_path, file_list_train)\n",
        "dataset_val = TGSSaltDataset(train_path, file_list_val, is_valid=True)\n",
        "\n",
        "# First train\n",
        "model = SaltNet().cuda()\n",
        "\n",
        "epoch = 30\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "load_checkpoint('drive/model/seed{}_{}_scSE_binary_model2.pth'.format(seed, fold), model, optimizer)\n",
        "# load_checkpoint('drive/model/resnet34_2nd.model', model, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0j4CIfXkO95i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "test_path = os.path.join(directory, 'test')\n",
        "test_file_list = glob.glob(os.path.join(test_path, 'images', '*.png'))\n",
        "test_file_list = [f.split('/')[-1].split('.')[0] for f in test_file_list]\n",
        "print('First 3 names of test files:', test_file_list[:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yDCXgPHmtU3v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "\n",
        "def downsample(img):\n",
        "    img = np.squeeze(img)\n",
        "    img = img[13:128 - 14, 13:128 - 14]\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZwRxLD-eO98n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f\"Test size: {len(test_file_list)}\")\n",
        "test_dataset = TGSSaltDataset(test_path, test_file_list, is_test = True)\n",
        "\n",
        "all_predictions = []\n",
        "model.set_mode('test')\n",
        "for image in tqdm(data.DataLoader(test_dataset, batch_size = 15)):\n",
        "    image1 = image[0].type(torch.FloatTensor).cuda()\n",
        "    y_pred, logit_pixel, logit_image = model(image1)\n",
        "    y_pred = y_pred.cpu().data.numpy()\n",
        "    y_pred = np.array([downsample(x) for x in y_pred])\n",
        "    \n",
        "    image2 = image[1].type(torch.FloatTensor).cuda()\n",
        "    y_pred_2, logit_pixel, logit_image = model(image2)\n",
        "    y_pred_2 = y_pred_2.cpu().data.numpy()\n",
        "    y_pred_2 = np.array([downsample(x) for x in y_pred_2])\n",
        "    y_pred_2 = np.array([cv2.flip(x, 1) for x in y_pred_2])\n",
        "    \n",
        "    y_pred = (y_pred + y_pred_2) / 2\n",
        "    all_predictions.append(y_pred)\n",
        "all_predictions_stacked = np.vstack(all_predictions)[:, :, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yGwPXl3eO-CO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_predictions_stacked.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WHX128nOuFqE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_depth_channels(image): # (101, 101, 3)\n",
        "    image = image.astype('float32')\n",
        "    h, w, _ = image.shape\n",
        "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
        "        image[row, :, 1] = const\n",
        "    image[:, :, 2] = image[:, :, 0] * image[:, :, 1]\n",
        "    image[:, :, 1] = image[:, :, 2]\n",
        "    return image\n",
        "\n",
        "def load_check_image(path, mask = False):\n",
        "\n",
        "    img = cv2.imread(str(path))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    ref_img = cv2.flip(img, 1)\n",
        "    img = add_depth_channels(img)\n",
        "    ref_img = add_depth_channels(ref_img)\n",
        "    \n",
        "    if mask:\n",
        "        img = img[:, :, 0:1] // 255        \n",
        "        return torch.from_numpy(np.transpose(img, (2, 0, 1)).astype('float32'))\n",
        "    else:\n",
        "        img = cv2.copyMakeBorder(img, 13, 14, 13, 14, cv2.BORDER_REPLICATE)\n",
        "        ref_img = cv2.copyMakeBorder(ref_img, 13, 14, 13, 14, cv2.BORDER_REPLICATE)\n",
        "        img = img[:, :, 0:1] / 255.0\n",
        "        ref_img = ref_img[:, :, 0:1] / 255.0\n",
        "        return torch.from_numpy(np.transpose(img, (2, 0, 1)).astype('float32')), torch.from_numpy(np.transpose(ref_img, (2, 0, 1)).astype('float32'))\n",
        "      \n",
        "class TGSSaltCheckDataset(data.Dataset):\n",
        "    def __init__(self, root_path, file_list):\n",
        "        self.root_path = root_path\n",
        "        self.file_list = file_list\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if index not in range(0, len(self.file_list)):\n",
        "            return self.__getitem__(np.random.randint(0, self.__len__()))\n",
        "        \n",
        "        file_id = self.file_list[index]\n",
        "        \n",
        "        image_folder = os.path.join(self.root_path, \"images\")\n",
        "        image_path = os.path.join(image_folder, file_id + \".png\")\n",
        "        \n",
        "        mask_folder = os.path.join(self.root_path, \"masks\")\n",
        "        mask_path = os.path.join(mask_folder, file_id + \".png\")\n",
        "        \n",
        "        image, ref_image = load_check_image(image_path)\n",
        "        mask = load_check_image(mask_path, mask = True)\n",
        "        return image, ref_image, mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kC-HaF_4PM9P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_val = TGSSaltCheckDataset(train_path, file_list_val)\n",
        "\n",
        "val_predictions = []\n",
        "val_masks = []\n",
        "model.set_mode('valid')\n",
        "for image, ref_image, mask in tqdm(data.DataLoader(dataset_val, batch_size = 15)):\n",
        "    image = Variable(image.type(torch.FloatTensor).cuda())\n",
        "    y_pred, logit_pixel, logit_image = model(image)\n",
        "    y_pred = y_pred.cpu().data.numpy()\n",
        "    y_pred = np.array([downsample(x) for x in y_pred])\n",
        "    \n",
        "    image = Variable(ref_image.type(torch.FloatTensor).cuda())\n",
        "    y_pred_2, logit_pixel, logit_image = model(image)\n",
        "    y_pred_2 = y_pred_2.cpu().data.numpy()\n",
        "    y_pred_2 = np.array([downsample(x) for x in y_pred_2])\n",
        "    y_pred_2 = np.array([cv2.flip(x, 1) for x in y_pred_2])\n",
        "\n",
        "    y_pred = (y_pred + y_pred_2) / 2\n",
        "    val_predictions.append(y_pred)\n",
        "    val_masks.append(mask)\n",
        "    \n",
        "val_predictions_stacked = np.vstack(val_predictions)[:, :, :]\n",
        "\n",
        "val_masks_stacked = np.vstack(val_masks)[:, 0, :, :]\n",
        "val_masks_stacked.shape, val_predictions_stacked.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SmyVbFIoPNAT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Score the model and do a threshold optimization by the best IoU.\n",
        "\n",
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "\n",
        "\n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n",
        "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
        "#     temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))\n",
        "    #print(temp1)\n",
        "    intersection = temp1[0]\n",
        "    #print(\"temp2 = \",temp1[1])\n",
        "    #print(intersection.shape)\n",
        "   # print(intersection)\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    #print(np.histogram(labels, bins = true_objects))\n",
        "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
        "    #print(\"area_true = \",area_true)\n",
        "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "  \n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    intersection[intersection == 0] = 1e-9\n",
        "    \n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "auXQei5NFoHx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# thresholds = np.linspace(0.3, 0.7, 31)\n",
        "# ious = np.array([iou_metric_batch(val_masks_stacked, np.int32(val_predictions_stacked > threshold)) for threshold in tqdm(thresholds)])\n",
        "\n",
        "## Scoring for last model, choose threshold by validation data \n",
        "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
        "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
        "thresholds = np.log(thresholds_ori/(1-thresholds_ori))\n",
        "\n",
        "ious = np.array([iou_metric_batch(val_masks_stacked, val_predictions_stacked > threshold) for threshold in tqdm(thresholds)])\n",
        "print(ious)\n",
        "\n",
        "threshold_best_index = np.argmax(ious) \n",
        "iou_best = ious[threshold_best_index]\n",
        "threshold_best = thresholds[threshold_best_index]\n",
        "\n",
        "plt.plot(thresholds, ious)\n",
        "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.ylabel(\"IoU\")\n",
        "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gpROudyxPNFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "threshold = threshold_best\n",
        "binary_prediction = (all_predictions_stacked > 0).astype(int)\n",
        "\n",
        "def rle_encoding(x):\n",
        "    dots = np.where(x.T.flatten() == 1)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if (b > prev+1): run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return run_lengths\n",
        "\n",
        "all_masks = []\n",
        "for p_mask in list(binary_prediction):\n",
        "    p_mask = rle_encoding(p_mask)\n",
        "    all_masks.append(' '.join(map(str, p_mask)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Br2UPcBWPNDn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submit = pd.DataFrame([test_file_list, all_masks]).T\n",
        "submit.columns = ['id', 'rle_mask']\n",
        "submit.to_csv('seed78_fold_4_binary.csv', index = False)\n",
        "submit.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mbdAy4PHTtLA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('seed78_fold_4_binary.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5R8YHPUHGpxK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fLVwKY55KejB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}